{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfeFDD4uz_lP"
   },
   "source": [
    "#**SEMANA  Introducción a la programación con Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9rIWonvAjTK"
   },
   "source": [
    "Esta semana analizaremos la libreria Scikit-Learn:\n",
    "\n",
    "* ¿Qué es Sckit-Learn?\n",
    "* Preprocesamiento de datos.\n",
    "* Desafío final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFLdDxhD0IA8"
   },
   "source": [
    "##**¿Qué es Scikit-Learn?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vemi0V9-ClMG"
   },
   "source": [
    "* Scikit-learn es una biblioteca de Python diseñada para Machine Learning.\n",
    "\n",
    "* Es ampliamente utilizada por su simplicidad y variedad de herramientas para tareas como clasificación, regresión, agrupamiento, reducción de dimensionalidad y preprocesamiento de datos.\n",
    "\n",
    "**Características principales:**\n",
    "* Soporta diversos algoritmos de ML.\n",
    "* Incluye herramientas para preprocesamiento de datos.\n",
    "* Fácil integración con otras bibliotecas como NumPy, Pandas y Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcPqYJNk19CT"
   },
   "source": [
    "##**Preprocesamiento de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFCvlZ-MC8BX"
   },
   "source": [
    "Scikit-learn ofrece varias herramientas para transformar y preparar datos antes de aplicar algoritmos de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHcSsDDX2SyO"
   },
   "source": [
    "###**1. Escalado de datos**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQR4FU6BDQD2"
   },
   "source": [
    "* El escalado ajusta los valores de las características para que estén dentro de un rango específico o tengan características estadísticas deseadas.\n",
    "\n",
    "* Los algoritmos de ML funcionan mejor cuando los datos están normalizados o escalados a rangos específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g4jY77S2PJX"
   },
   "source": [
    "####**1.1 MinMaxScaler**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gvJGrbWD0aO"
   },
   "source": [
    "Escala los datos a un rango específico, generalmente [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgbiB8U31Jp4"
   },
   "outputs": [],
   "source": [
    "# Ejemplo\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Datos de ejemplo\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [10, 20, 30], 'B': [5, 15, 25]})\n",
    "# Salida del dataframe original\n",
    "print (\"DataFrame original :\\n\", df)\n",
    "\n",
    "# Escalar al rango [0, 1]\n",
    " # Inicialización del Escalador\n",
    " # Se crea una instancia de la clase MinMaxScaler.\n",
    " # Este escalador transformará los valores de cada columna para que estén\n",
    " #dentro del rango [0, 1], utilizando la fórmula: valor escalado = valor-minimo (máximo-mínimo)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Transformación y Escalado\n",
    " # scaler.fit_transform(df)\n",
    " # Calcula el mínimo y el máximo de cada columna en el DataFrame df.\n",
    " # Escala cada valor de acuerdo con la fórmula anterior.\n",
    " # pd.DataFrame(..., columns=df.columns):\n",
    " # Convierte el resultado (que es un array de NumPy) nuevamente en un DataFrame de Pandas.\n",
    " # Asigna los mismos nombres de columnas que el DataFrame original (df.columns).\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "print(\"Datos escalados al rango [0, 1]:\\n\", df_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHiIsbku5u5F"
   },
   "source": [
    "####**1.2 StandardScaler**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj-PSC0sFm5H"
   },
   "source": [
    "Normaliza los datos para que tengan una media de 0 y una desviación estándar de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8_gkGdf5_mb"
   },
   "outputs": [],
   "source": [
    "# Ejemplo\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Datos de ejemplo\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [10, 20, 30], 'B': [5, 15, 25]})\n",
    "# Salida del dataframe original\n",
    "print (\"DataFrame original :\\n\", df)\n",
    "\n",
    "# Escalar los datos con media=0 y std=1\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(\"Datos escalados con StandardScaler:\\n\", df_standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50BfmbDI77-M"
   },
   "source": [
    "####**1.3. RobustScaler**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exo61mS2F7Ka"
   },
   "source": [
    "Escala los datos usando la mediana y el rango intercuartílico (IQR), lo que lo hace resistente a valores atípicos.\n",
    "\n",
    "El rango intercuartílico (IQR, por sus siglas en inglés) es una medida de dispersión que representa la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1) de un conjunto de datos.\n",
    "\n",
    "Al aplicar RobustScaler, la transformación reduce la influencia de los valores atípicos al basarse en los cuartiles, en lugar de la media y la desviación estándar, que son sensibles a los outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPCylNgd8HC4"
   },
   "outputs": [],
   "source": [
    "# Ejemplo\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Datos de ejemplo\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [10, 20, 30], 'B': [5, 15, 25]})\n",
    "# Salida del dataframe original\n",
    "print (\"DataFrame original :\\n\", df)\n",
    "\n",
    "# Escalar los datos con RobustScaler\n",
    "scaler = RobustScaler()\n",
    "df_robust = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(\"Datos escalados con RobustScaler:\\n\", df_robust)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E23mDEeN8x-L"
   },
   "source": [
    "###**2. Imputación de Valores Faltantes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyIsY2b4GMn1"
   },
   "source": [
    "scikit-learn permite rellenar valores faltantes (NaN) con valores estadísticos como la media, mediana o un valor constante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbr3W-G09NmQ"
   },
   "source": [
    "####**2.1 Imputación con la Media**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiIG0JDt9S3O"
   },
   "outputs": [],
   "source": [
    "# Ejemplo\n",
    "# SimpleImputer: Herramienta de scikit-learn para manejar valores faltantes\n",
    "#en datos.\n",
    "#Permite reemplazar los valores faltantes con una estrategia definida,\n",
    "#como la media, mediana, o un valor constante.\n",
    "from sklearn.impute import SimpleImputer\n",
    "# numpy: Biblioteca usada para trabajar con arrays\n",
    "#y para representar valores faltantes con np.nan\n",
    "import numpy as np\n",
    "\n",
    "# Datos con valores faltantes\n",
    "data = pd.DataFrame({'A': [1, 2, np.nan], 'B': [4, np.nan, 6]})\n",
    "print (\"DataFrame original :\\n\", data)\n",
    "\n",
    "# Imputar con la media\n",
    "# SimpleImputer se configura con la estrategia mean,\n",
    "# lo que significa que los valores faltantes serán reemplazados por la media\n",
    "# de cada columna.\n",
    "# Otras estrategias disponibles:\n",
    "# median: Usa la mediana.\n",
    "# most_frequent: Usa el valor más frecuente.\n",
    "# constant: Usa un valor constante especificado por el usuario.\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Imputación de Valores Faltantes:\n",
    "# imputer.fit_transform(data):\n",
    "# fit: Calcula la media de cada columna.\n",
    "# transform: Reemplaza los valores faltantes por la media calculada.\n",
    "# Los resultados se convierten nuevamente a un DataFrame con los mismos\n",
    "# nombres de columnas.\n",
    "\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "print(\"Datos después de la imputación con la media:\\n\", data_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXTAXgbm_1WQ"
   },
   "source": [
    "###**3. Codificación de datos categóricos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3Ne8Zi-KGfY"
   },
   "source": [
    "Los modelos de machine learning requieren datos numéricos, por lo que es necesario transformar datos categóricos en números."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgbkxDL3KULd"
   },
   "source": [
    "####**3.1 One-Hot Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOR7QhDCADj1"
   },
   "source": [
    "Convierte categorías en columnas binarias o one-hot-encoding.\n",
    "\n",
    "**Columnas Binarias**\n",
    ">Una columna binaria es una representación en la que cada categoría de una variable categórica se representa como un único bit o valor binario (0 o 1).\n",
    "\n",
    ">>**Estructura:**\n",
    ">>>Generalmente, toda la información de las categorías está contenida en una sola columna.\n",
    "Por ejemplo:\n",
    "\n",
    ">>>Categoría A → 0\n",
    "\n",
    ">>>Categoría B → 1\n",
    "\n",
    ">>**Ejemplo:** Si tenemos la columna Género:\n",
    ">>>Original: ['Hombre', 'Mujer', 'Hombre'].\n",
    "\n",
    ">>>Representación Binaria: [0, 1, 0]\n",
    "\n",
    ">>**Usos Comunes:**\n",
    ">>>Variables con dos categorías (variables binarias o dicotómicas).\n",
    "\n",
    ">>**Ejemplo:**\n",
    ">>>Género (Hombre/Mujer),\n",
    "\n",
    ">>>¿Compra realizada? (Sí/No).\n",
    "\n",
    ">>**Ventaja:**\n",
    ">>>Es más eficiente en términos de almacenamiento y procesamiento porque solo necesita una columna.\n",
    "\n",
    ">>**Limitación:**\n",
    ">>>Solo se puede usar cuando la variable tiene exactamente dos categorías.\n",
    "\n",
    "\n",
    "**One-Hot Encoding**\n",
    ">Crea una columna separada para cada categoría de una variable categórica, y marca con un 1 si la fila pertenece a esa categoría o con un 0 si no.\n",
    "\n",
    ">>Estructura:\n",
    ">>>Cada categoría tiene su propia columna binaria.\n",
    ">>>Categoría A → [1, 0, 0]\n",
    ">>>Categoría B → [0, 1, 0]\n",
    ">>>Categoría C → [0, 0, 1]\n",
    "\n",
    ">>Ejemplo:\n",
    ">>>Si tenemos la columna Género:\n",
    ">>>Original: ['Hombre', 'Mujer', 'Hombre']\n",
    "\n",
    ">>>[One-Hot Encoding](https://drive.google.com/file/d/1ssf2uNd7Hu55GG04LjBkd8RjbwjrPZgH/view?usp=sharing):\n",
    "\n",
    "\n",
    ">>**Usos Comunes:**\n",
    ">>>Variables con tres o más categorías.\n",
    "\n",
    ">>**Ejemplo:**\n",
    ">>>Color (Rojo, Azul, Verde),\n",
    "\n",
    ">>>Nivel Educativo (Primaria, Secundaria, Universitaria).\n",
    "\n",
    ">>**Ventaja:**\n",
    ">>>Funciona con cualquier cantidad de categorías y mantiene las relaciones de exclusividad entre categorías.\n",
    "\n",
    ">>**Limitación:**\n",
    ">>>Aumenta significativamente el número de columnas cuando hay muchas categorías.\n",
    "\n",
    "[Tabla resumen](https://drive.google.com/file/d/1ZxU8jnVTCmVSjI5Ze8F28zQdVUn3lOel/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZqjtpgwARfl"
   },
   "outputs": [],
   "source": [
    "# Ejemplo\n",
    "\n",
    "# Importación del OneHotEncoder\n",
    "# Esta herramienta de scikit-learn se utiliza para convertir datos categóricos\n",
    "# en un formato que los modelos de machine learning puedan manejar: columnas binarias\n",
    "# o One-Hot Encoding.\n",
    "# Cada categoría única se convierte en una columna separada con valores 1\n",
    "# (si pertenece a esa categoría) o 0 (si no pertenece).\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Datos categóricos\n",
    "data = pd.DataFrame({'Género': ['Hombre', 'Mujer', 'Hombre']})\n",
    "\n",
    "# Codificación One-Hot\n",
    "#cInicialización del Codificador One-Hot:\n",
    "# OneHotEncoder convierte los valores categóricos en columnas binarias.\n",
    "# Parámetro sparse=False:\n",
    "# Por defecto, OneHotEncoder devuelve una matriz dispersa (sparse matrix) para ahorrar memoria.\n",
    "# Matriz densa:\n",
    "# Es una matriz \"normal\", donde se almacenan todos los valores,\n",
    "# incluyendo los ceros. Cada elemento se guarda, sin importar si es 0 o cualquier otro número.\n",
    "# Es más fácil de usar y manipular, pero puede ocupar mucha memoria si la matriz es grande.\n",
    "# Matriz dispersa:\n",
    "# Solo guarda los valores no nulos (por ejemplo, los valores distintos de cero).\n",
    "# Es muy eficiente en memoria cuando la matriz tiene muchos ceros,\n",
    "# como en la codificación one-hot, porque no guarda los ceros, solo los valores que realmente importan.\n",
    "\n",
    "# Aquí usamos sparse=False para obtener una matriz densa más fácil de manipular con Pandas.\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Codificación One-Hot:\n",
    "# encoder.fit_transform(data):\n",
    "# fit: Aprende las categorías únicas en la columna Género\n",
    "# (en este caso, \"Hombre\" y \"Mujer\").\n",
    "# transform: Convierte los datos categóricos en columnas binarias.\n",
    "# pd.DataFrame(...):\n",
    "# Convierte el resultado de fit_transform (un array de NumPy) nuevamente en un DataFrame.\n",
    "# encoder.get_feature_names_out():\n",
    "# Genera los nombres de las nuevas columnas en función de las categorías únicas encontradas.\n",
    "# Por ejemplo, genera las columnas Género_Hombre y Género_Mujer.\n",
    "data_encoded = pd.DataFrame(encoder.fit_transform(data), columns=encoder.get_feature_names_out(['Género']))\n",
    "print(\"Datos codificados con One-Hot Encoding:\\n\", data_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAO0Ia0rGs1y"
   },
   "outputs": [],
   "source": [
    "# Otro ejemplo agregando más categorías\n",
    "# Supongamos que añadimos las cateogrías \"Otro\", \"prefiero no decirlo\":\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Datos con más categorías\n",
    "data = pd.DataFrame({'Género': ['Hombre', 'Mujer', 'Otro', 'Prefiero no decirlo', 'Hombre', 'Otro']})\n",
    "\n",
    "# Crear el codificador One-Hot\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Cambiar sparse_output para scikit-learn >=1.2.0\n",
    "data_encoded = pd.DataFrame(encoder.fit_transform(data[['Género']]),\n",
    "                            columns=encoder.get_feature_names_out(['Género']))\n",
    "\n",
    "print(\"Datos codificados con One-Hot Encoding:\\n\", data_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj54aFNyKoy1"
   },
   "source": [
    "####**3.2 Binarización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-U9qlc9Q4Xw"
   },
   "source": [
    "Convierte valores numéricos en valores binarios en función de un umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEwKdqRgLICh"
   },
   "outputs": [],
   "source": [
    "# Importación del Binarizer:\n",
    "# Se importa Binarizer desde scikit-learn.\n",
    "# Binarizer es una herramienta que se utiliza para transformar\n",
    "# datos numéricos en datos binarios (0 o 1) en función de un umbral (threshold).\n",
    "# Es útil cuando deseamos convertir datos continuos en datos discretos\n",
    "# según un valor límite (umbral).\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = pd.DataFrame({'Notas': [7, 4, 3, 5, 6]})\n",
    "\n",
    "# Binarización con umbral 5\n",
    "# Inicialización del Binarizer:\n",
    "# Se crea un objeto binarizer utilizando la clase Binarizer y se le asigna\n",
    "# un umbral de 5 (threshold=5).\n",
    "# Este umbral es el valor de corte para convertir las notas en valores binarios.\n",
    "# Si una nota es mayor o igual a 5, se convierte en 1. Si es menor que 5, se convierte en 0.\n",
    "binarizer = Binarizer(threshold=5)\n",
    "\n",
    "# Transformación de los Datos:\n",
    "# binarizer.fit_transform(data):\n",
    "# fit: Calcula el umbral (en este caso no es necesario porque ya lo hemos definido, pero es parte del proceso).\n",
    "# transform: Aplica la binarización a los datos.\n",
    "# Las notas que son mayores o iguales a 5 se convierten en 1, y las notas menores a 5 se convierten en 0.\n",
    "# pd.DataFrame(...):\n",
    "# Convierte el array resultante en un DataFrame de Pandas con una nueva columna llamada Notas Binarizadas.\n",
    "data_binarized = pd.DataFrame(binarizer.fit_transform(data), columns=['Notas Binarizadas'])\n",
    "print(\"Datos binarizados:\\n\", data_binarized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_Cbu_lOTvx9"
   },
   "source": [
    "##**Desafío final**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyzrN0a-T617"
   },
   "source": [
    "**Objetivo:** Analizar y procesar los datos de estudiantes para descubrir patrones, realizar transformaciones, y crear visualizaciones utilizando NumPy, Pandas, Sckit-Learn y Matplotlib.\n",
    "\n",
    "1. **Cargue el archivo datos_estudiantes_desafio.csv**\n",
    "* El archivo datos_estudiantes_desafio.csv contiene 20 mil registros:\n",
    " * Estudiante_ID: Identificador único del estudiante.\n",
    " * Edad: Edad del estudiante.\n",
    " * Horas_de_estudio: Número promedio de horas de estudio por semana.\n",
    " * Nota_Matemáticas, Nota_Lenguaje, Nota_Ciencias: Calificaciones en cada asignatura.\n",
    " * Genero: Género del estudiante.\n",
    " * Comuna: Comuna donde reside el estudiante.\n",
    "\n",
    "\n",
    "2. **Exploración de datos:**\n",
    "* Verificar las primeras y últimas filas del conjunto de datos (head y tail).\n",
    "* Mostrar la forma del conjunto de datos (shape).\n",
    "* Mostrar estadísticas descriptivas de las columnas numéricas (describe).\n",
    "* Pregunta: ¿Cuál es el rango de edad más común entre los estudiantes?\n",
    "\n",
    "\n",
    "3. **Limpieza de Datos:**\n",
    "* Verificar y manejar valores nulos o faltantes en el conjunto de datos.\n",
    " * Identificar si hay valores nulos (isnull).\n",
    " * Si hay valores nulos, reemplazarlos por la mediana en las columnas numéricas.\n",
    "* Pregunta: ¿Cuál es el porcentaje de datos faltantes en cada columna?\n",
    "\n",
    "\n",
    "4. **Análisis Exploratorio:**\n",
    "* Calcular las siguientes métricas para las columnas de calificaciones:\n",
    " * Promedio general por asignatura.\n",
    " * Promedio por estudiante.\n",
    "* Determinar el porcentaje de estudiantes que tienen una calificación mayor o igual a 60 en las tres asignaturas.\n",
    "* Pregunta: ¿Qué comuna tiene el promedio más alto en matemáticas?\n",
    "\n",
    "\n",
    "5. **Filtros y Agrupaciones:**\n",
    "* Filtrar estudiantes con calificaciones promedio mayores a 80 y mostrarlos en un nuevo DataFrame.\n",
    "* Agrupar los datos por género y calcular el promedio de calificaciones por género.\n",
    "\n",
    "\n",
    "6. **Preprocesamiento de Datos:**\n",
    "* Normalizar las columnas de calificaciones y horas de estudio usando NumPy o Scikit-learn.\n",
    "* Convertir las categorías de la columna Genero en variables numéricas (One-Hot Encoding).\n",
    "* Pregunta: ¿Cuál es el rango de las calificaciones después de la normalización.\n",
    "\n",
    "\n",
    "7. **Visualizaciones:**\n",
    "* Crear gráficos utilizando Matplotlib (https://matplotlib.org/stable/gallery/index.html).\n",
    "  * Distribución de calificaciones por asignatura.\n",
    "  * Promedio de calificaciones por comuna (gráfico de barras).\n",
    "* Crear un gráfico de dispersión que relacione Horas_de_estudio y Nota_Matemáticas.\n",
    "* Pregunta: ¿Qué patrón observas entre horas de estudio y desempeño en matemáticas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ec93c",
   "metadata": {},
   "source": [
    "## Parte 3 - Análisis visual y preprocesamiento con Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563c504",
   "metadata": {},
   "source": [
    "En esta parte del desafío, trabajarás con visualización de datos y técnicas de preprocesamiento.\n",
    "\n",
    "Usando la librería `Seaborn` o `Matplotlib`, debes realizar los siguientes pasos:\n",
    "\n",
    "### Visualización exploratoria:\n",
    "1. Crea histogramas de las variables `edad`, `notas`, y `tiempo_estudio` para ver su distribución.\n",
    "2. Crea un gráfico de dispersión entre `tiempo_estudio` y `notas` para ver si hay una posible correlación.\n",
    "3. Usa `sns.boxplot()` para comparar las notas de estudiantes por género (`genero`).\n",
    "4. Calcula y visualiza la matriz de correlación entre las variables numéricas usando `sns.heatmap()`.\n",
    "\n",
    "### Preprocesamiento con Scikit-learn:\n",
    "1. Escala las columnas numéricas (`edad`, `tiempo_estudio`, `notas`) usando `StandardScaler`.\n",
    "2. Convierte las variables categóricas como `genero` o `tipo_escuela` en variables numéricas usando `OneHotEncoder`.\n",
    "3. Crea un nuevo DataFrame con los datos preprocesados y muéstralo.\n",
    "\n",
    "> **Nota:** Esta sección solo contempla el preprocesamiento, no se debe aplicar ningún modelo de ML todavía.\n",
    "\n",
    "Puedes apoyarte en el contenido de los cuadernos anteriores para guiar tu análisis.\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wfeFDD4uz_lP",
    "bFLdDxhD0IA8",
    "vcPqYJNk19CT",
    "iHcSsDDX2SyO",
    "2g4jY77S2PJX",
    "WHiIsbku5u5F",
    "50BfmbDI77-M",
    "E23mDEeN8x-L",
    "bbr3W-G09NmQ",
    "XXTAXgbm_1WQ",
    "QgbkxDL3KULd",
    "sj54aFNyKoy1",
    "4_Cbu_lOTvx9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
